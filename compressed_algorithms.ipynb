{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression algorithms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huffman encoding\n",
    "Huffman encoding is a variable-length prefix code used for lossless data compression. It assigns shorter codes to frequently occurring symbols and longer codes to less frequent symbols. \n",
    "\n",
    "The algorithm works by constructing a table that maps each symbol to its corresponding variable-length code. The table is constructed by starting with the two least frequent symbols and combining them into a new symbol with a frequency equal to the sum of their frequencies. This process is repeated until all symbols are combined into a single root node, which represents the entire symbol set. \n",
    "\n",
    "The resulting codes are formed by concatenating the binary digits of the path from the root node to the leaf node representing each symbol. The codes are stored in the Huffman table and used to encode the input data. \n",
    "\n",
    "### Encoding:\n",
    "1. Read a file, count the frequency of occurrence of every symbol (func make_items), make list of tuples (symbol, frequency)\n",
    "2. Add two the least frequent symbols and make a tuple ((symbol_1, symbol_2), summary_frequency)\n",
    "3. Replace their tuples with this one in the list\n",
    "4. Repeat step 2 and step 3 until list contains only 1 element\n",
    "5. Divide the existing set into two parts that existed during the previous addition\n",
    "6. Add 0 to the code of the set with a higher frequency and 1 to the set with a lower frequency\n",
    "7. Repeat until you'll have a unique code for every symbol (dict: {symbol: code})\n",
    "\n",
    "### Decoding:\n",
    "1. Take one symbol from file, check if it's a code\n",
    "2. Append to it next one if not, else write this code's key\n",
    "3. Repeat steps 1 and 2 until you will get your original message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TestResults(failed=0, attempted=13)\n"
     ]
    }
   ],
   "source": [
    "class Huffman:\n",
    "    def __init__(self, file_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Initialize a new Huffman object.\n",
    "\n",
    "        :param file_name: Name of the file to be encoded/decoded.\n",
    "        :type file_name: str\n",
    "        >>> h = Huffman(\"test.txt\")\n",
    "        >>> h.file_name\n",
    "        'test.txt'\n",
    "        \"\"\"\n",
    "        self.file_name = file_name\n",
    "        self.codes = {}\n",
    "\n",
    "    def encode_huffman(self) -> str:\n",
    "        \"\"\"\n",
    "        Encode the contents of the input file using Huffman coding.\n",
    "\n",
    "        :return: Encoded binary string.\n",
    "        :rtype: str\n",
    "        >>> h = Huffman(\"test.txt\")\n",
    "        >>> h.encode_huffman()\n",
    "        '011110100101000000101000011100001101010011000110001010101110011010'\n",
    "        \"\"\"\n",
    "        def assign_symbols(node, code = ''):\n",
    "            if isinstance(node, tuple):\n",
    "                assign_symbols(node[0], code + '0')\n",
    "                assign_symbols(node[1], code + '1')\n",
    "            else:\n",
    "                self.codes[node] = code\n",
    "        assign_symbols(self.add_probabilities()[0][0])\n",
    "        with open(self.file_name, 'r', encoding='utf-8') as file:\n",
    "            data = file.read()\n",
    "        res = []\n",
    "        for character in data:\n",
    "            res.append(self.codes[character])\n",
    "        return ''.join(res)\n",
    "\n",
    "    def huffman_decode(self, code: str) -> str:\n",
    "        \"\"\"\n",
    "        Decode a binary string using Huffman coding.\n",
    "\n",
    "        :param code: Encoded binary string to be decoded.\n",
    "        :type code: str\n",
    "        :return: Decoded string.\n",
    "        :rtype: str\n",
    "        >>> h = Huffman(\"test.txt\")\n",
    "        >>> h.huffman_decode(h.encode_huffman())\n",
    "        'this is a test message'\n",
    "        \"\"\"\n",
    "        symbol = []\n",
    "        new_message = []\n",
    "        for i in code:\n",
    "            symbol.append(str(i))\n",
    "            for key in self.codes:\n",
    "                if ''.join(symbol) == self.codes[key]:\n",
    "                    new_message.append(key)\n",
    "                    symbol = []\n",
    "        return ''.join(new_message)\n",
    "        # with open('decoded.txt', 'w', encoding='utf-8') as new_file:\n",
    "        #     new_file.write(''.join(new_message))\n",
    "\n",
    "    def make_items(self) -> list:\n",
    "        \"\"\"\n",
    "        Create a list of unique characters and their frequencies in the input file.\n",
    "\n",
    "        :return: List of tuples with character-frequency pairs.\n",
    "        :rtype: list\n",
    "        >>> h = Huffman(\"test.txt\")\n",
    "        >>> h.make_items()\n",
    "        [('h', 0.045454545454545456), ('m', 0.045454545454545456), ('g', 0.045454545454545456), ('i', 0.09090909090909091), ('a', 0.09090909090909091), ('t', 0.13636363636363635), ('e', 0.13636363636363635), (' ', 0.18181818181818182), ('s', 0.22727272727272727)]\n",
    "        \"\"\"\n",
    "        dct = {}\n",
    "        count = 0\n",
    "        with open(self.file_name, 'r', encoding='utf-8') as file:\n",
    "            lines = file.read()\n",
    "            for line in lines:\n",
    "                for i in line:\n",
    "                    count += 1\n",
    "                    if i not in dct:\n",
    "                        dct[i] = 1\n",
    "                    else:\n",
    "                        dct[i] += 1\n",
    "        for key in dct:\n",
    "            dct[key] = dct[key]/count\n",
    "        sorted_items = sorted(dct.items(), key=lambda x: x[1])\n",
    "        return sorted_items\n",
    "\n",
    "    def add_probabilities(self) -> list:\n",
    "        \"\"\"\n",
    "        Create a tree of nodes representing the Huffman encoding of the input file.\n",
    "\n",
    "        :return: List of tuples representing the nodes of the Huffman tree.\n",
    "        :rtype: list\n",
    "        >>> h = Huffman(\"test.txt\")\n",
    "        >>> h.add_probabilities()\n",
    "        [((((' ', ('i', 'g')), ('e', 't')), ('s', (('m', 'h'), 'a'))), 0.9999999999999999)]\n",
    "        \"\"\"\n",
    "        items = self.make_items()\n",
    "        while len(items) > 1:\n",
    "            first_elem, prob_1 = items.pop(0)\n",
    "            second_elem, prob_2 = items.pop(0)\n",
    "            items.append(((second_elem, first_elem),(prob_2+prob_1)))\n",
    "            items = sorted(items, key=lambda x: x[1])\n",
    "        return items\n",
    "    \n",
    "    def huffman_dict(self):\n",
    "        \"\"\"\n",
    "        Return a dictionary of Huffman codes.\n",
    "\n",
    "        :return: Dictionary with characters as keys and their corresponding Huffman codes as values.\n",
    "        :rtype: dict\n",
    "        >>> h = Huffman(\"test.txt\")\n",
    "        >>> h.encode_huffman()\n",
    "        '011110100101000000101000011100001101010011000110001010101110011010'\n",
    "        >>> len(h.huffman_dict())\n",
    "        9\n",
    "        \"\"\"\n",
    "        return self.codes\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import doctest\n",
    "    print(doctest.testmod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so i love bananas very much'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_text = Huffman('test.txt')\n",
    "new_text.encode_huffman()\n",
    "new_text.huffman_decode(new_text.encode_huffman())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lz77 algorithm\n",
    "\n",
    "LZ77 is a lossless data compression algorithm that was published by Abraham Lempel and Jacob Ziv in 1977. It is a dictionary-based algorithm that achieves compression by replacing repeated occurrences of data with references to a single copy of that data existing earlier in the uncompressed data stream.\n",
    "\n",
    "Encoder:\n",
    "\n",
    "- There is given some string that contains text(ex. ‘abacacaccadba’)\n",
    "- Call *lz77_encode* function:\n",
    "    - Take first element of string and place it to out message\n",
    "    - Set <offset; length; next> to each word\n",
    "    - Using while loop analyse string until it’s empty\n",
    "    - Check different situations: different offsets, lengths or next values\n",
    "    - If initial message reaches the end, finish execution\n",
    "    - Outout list of tuples\n",
    "\n",
    "Decoder:\n",
    "\n",
    "- There is given code in the format [(0, 0, 'a'), (0, 0, 'b'), (1, 1, 'c'), (3, 3, None)]\n",
    "- If offset and length is 0, add 1 word\n",
    "- If offset and length is more than 0, analyse buffer(return offset symbols back, and copy elements of length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lz77:\n",
    "    \"\"\"\n",
    "    A class to perform LZ77 encoding and decoding on a given text.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The text to be encoded.\n",
    "    - buffer (int): The size of the buffer used for encoding. Default value is 5.\n",
    "\n",
    "    Attributes:\n",
    "    - buffer (int): The size of the buffer used for encoding.\n",
    "    - text (str): The text to be encoded.\n",
    "\n",
    "    Methods:\n",
    "    - lz77_encode: Encodes the text using LZ77 algorithm and returns the encoded message.\n",
    "    - lz77_decode: Decodes the encoded message using LZ77 algorithm and returns the original text.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    >>> lz = lz77('ababcbababaaaa')\n",
    "    >>> encoded_message = lz.lz77_encode()\n",
    "    >>> decoded_text = lz.lz77_decode(encoded_message)\n",
    "    >>> decoded_text\n",
    "    'ababcbababaaaa'\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, text: str, buffer = 5):\n",
    "        self.buffer = buffer\n",
    "        self.text = text\n",
    "    \n",
    "    def lz77_encode(self):\n",
    "        \"\"\"\n",
    "        Encodes the text using LZ77 algorithm and returns the encoded message.\n",
    "\n",
    "        Returns:\n",
    "        - message (list of tuples): The encoded message as a list of tuples, where each tuple represents a part of the text. \n",
    "            The first element of the tuple is the offset of the longest match found in the buffer, the second element is the length of the match, \n",
    "            and the third element is the next character in the text. If there is no match in the buffer, the first and second elements are 0, \n",
    "            and the third element is the next character in the text.\n",
    "        \n",
    "        Example usage:\n",
    "        ```\n",
    "        >>> lz = lz77('ababcbababaaaa')\n",
    "        >>> lz.lz77_encode()\n",
    "        [(0, 0, 'a'), (0, 0, 'b'), (1, 1, 'c'), (3, 3, None), (6, 1, None), (0, 0, 'a'), (0, 0, 'a'), (0, 0, 'a')]\n",
    "        ```\n",
    "        \"\"\"\n",
    "        message = [(0, 0, self.text[0])]\n",
    "        buff = self.text[0]\n",
    "        self.text = self.text[1:]\n",
    "        \n",
    "        while self.text:\n",
    "            length = 1\n",
    "            while length <= len(buff):\n",
    "                if self.text[0] not in buff:\n",
    "                    message.append((0, 0, self.text[0]))\n",
    "                elif self.text in buff:\n",
    "                    offset = len(buff) - buff.index(self.text[0])\n",
    "                    message.append((offset, length, None))\n",
    "                    return message\n",
    "                elif self.text[:length] in buff:\n",
    "                    length += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    offset = len(buff) - buff.index(self.text[0])\n",
    "                    message.append((offset, length-1, self.text[length-1]))\n",
    "                buff += self.text[:length]\n",
    "                self.text = self.text[length:]\n",
    "                buff = buff[-self.buffer:]\n",
    "                length = 1\n",
    "        # with open('lz77decoded.txt', 'w', encoding='utf-8') as file:\n",
    "        #     file.write('.'message)\n",
    "        return message\n",
    "    \n",
    "    def lz77_decode(self, message: list):\n",
    "        \"\"\"\n",
    "        Decodes the encoded message using LZ77 algorithm and returns the original text.\n",
    "\n",
    "        Args:\n",
    "        - message (list of tuples): The encoded message as a list of tuples, where each tuple represents a part of the text. \n",
    "            The first element of the tuple is the offset of the longest match found in the buffer, the second element is the length of the match, \n",
    "            and the third element is the next character in the text. If there is no match in the buffer, the first and second elements are 0, and the third element is the next character in the text.\n",
    "\n",
    "        Returns:\n",
    "        - decoded (str): The original text after decoding the message.\n",
    "\n",
    "        Example usage:\n",
    "        ```\n",
    "        >>> lz = lz77('ababcbababaaaa')\n",
    "        >>> encoded_message = lz.lz77_encode()\n",
    "        >>> lz.lz77_decode(encoded_message)\n",
    "        'ababcbababaaaa'\n",
    "        ```\n",
    "        \"\"\"\n",
    "        decoded = ''\n",
    "        for elem in message:\n",
    "            if (elem[0] and elem[1]) == 0:\n",
    "                decoded += elem[2]\n",
    "            else:\n",
    "                if elem[2] is not None:\n",
    "                    decoded += decoded[-elem[0]:(-elem[0]+elem[1])] + elem[2]\n",
    "                else:\n",
    "                    decoded += decoded[-elem[0]:(-elem[0]+elem[1])]\n",
    "        return decoded\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 'a'),\n",
       " (0, 0, 'b'),\n",
       " (0, 0, 'd'),\n",
       " (3, 2, 'b'),\n",
       " (3, 1, 'd'),\n",
       " (5, 2, 'c'),\n",
       " (5, 2, 'b'),\n",
       " (3, 1, None)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = lz77('abdabbadabcadba')\n",
    "data.lz77_encode()\n",
    "# data.decode(data.lz77_encode())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LZW algorithm\n",
    "\n",
    "LZW (Lempel-Ziv-Welch) is a lossless data compression algorithm developed by Abraham Lempel, Jacob Ziv, and Terry Welch in 1977.\n",
    "\n",
    "Encoder:\n",
    "\n",
    "- There is given some string that contains text(ex. ‘abacacaccadba’)\n",
    "- Call *lzw_compress* function:\n",
    "    - Test word's uniqueness and add them to empty array\n",
    "    - Set variable to save previous word(in the end if values are equal twice we have reached the end)\n",
    "    - Using while loop analyse string until it’s empty\n",
    "    - Append words and code of word at the same time\n",
    "    - If previous message == initial message break\n",
    "    - Return index of each entered word\n",
    "\n",
    "Decoder:\n",
    "\n",
    "- There is given code in the format [0, 1, 0, 2, 6, 6, 7, 3, 5] and first n values of words that have length 1.\n",
    "- If code < len(out message) append element to dictionary and out message\n",
    "- In other situation append dictionary[code] + dictionary[code][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Lempel Ziv Welch [LZW] algorithm\"\"\"\n",
    "\n",
    "class LZW:\n",
    "    \"\"\"Module to perform LZW algorithm\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def lzw_compress(initial_msg):\n",
    "        \"\"\"\n",
    "        Compresses a given string using the Lempel Ziv Welch algorithm.\n",
    "\n",
    "        Args:\n",
    "        initial_msg (str): The string to be compressed.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of integers representing the compressed message.\n",
    "\n",
    "        Example:\n",
    "        >>> LZW.lzw_compress(\"abacacaccadba\")\n",
    "        [0, 1, 0, 2, 6, 6, 7, 3, 5]\n",
    "        \"\"\"\n",
    "        words = []\n",
    "        # test word's uniqueness\n",
    "        for word in initial_msg:\n",
    "            if word not in words:\n",
    "                words.append(word)\n",
    "        code = []\n",
    "\n",
    "        # if values are equal twice we have reached the end\n",
    "        prev_message = initial_msg\n",
    "        while True:\n",
    "            index = 0\n",
    "\n",
    "            for index in range(len(initial_msg)):\n",
    "                if initial_msg[:index+2] not in words:\n",
    "                    words.append(initial_msg[:index+2])\n",
    "                    code.append(words.index(initial_msg[:index+2][:-1]))\n",
    "                    initial_msg = initial_msg[index+1:]\n",
    "                    break\n",
    "\n",
    "            if prev_message == initial_msg:\n",
    "                code.append(words.index(initial_msg))\n",
    "                break\n",
    "            prev_message = initial_msg\n",
    "\n",
    "        return code\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def lzw_decompress(compressed, first_n_vals):\n",
    "        \"\"\"\n",
    "        Decompresses a compressed message using the Lempel Ziv Welch algorithm.\n",
    "\n",
    "        Args:\n",
    "        compressed (list): A list of integers representing the compressed message.\n",
    "        first_n_vals (list): A list of characters representing the first n values of the original message.\n",
    "\n",
    "        Returns:\n",
    "        str: The decompressed message.\n",
    "\n",
    "        Example:\n",
    "        >>> LZW.lzw_decompress([0, 1, 0, 2, 6, 6, 7, 3, 5], ['a', 'b', 'c', 'd'])\n",
    "        'abacacaccadba'\n",
    "        \"\"\"\n",
    "        out_msg = []\n",
    "        dictionary = first_n_vals[:]\n",
    "        codes = compressed[:]\n",
    "\n",
    "        for idx, code in enumerate(codes):\n",
    "            out_msg.append(dictionary[code])\n",
    "            if idx + 1 >= len(codes):\n",
    "                break\n",
    "\n",
    "            if code < len(out_msg):\n",
    "                dictionary.append(dictionary[code] + dictionary[codes[idx + 1]][0])\n",
    "            else:\n",
    "                dictionary.append(dictionary[code] + dictionary[code][0])\n",
    "\n",
    "        return \"\".join(out_msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 2, 6, 6, 7, 3, 5]\n",
      "abacacaccadba\n"
     ]
    }
   ],
   "source": [
    "compress = LZW().lzw_compress(\"abacacaccadba\")\n",
    "print(compress)\n",
    "\n",
    "decompress = LZW().lzw_decompress([0, 1, 0, 2, 6, 6, 7, 3, 5], ['a', 'b', 'c', 'd'])\n",
    "print(decompress)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deflate algorithm\n",
    "\n",
    "Deflate is a lossless data compression algorithm that is commonly used in the compression of files in the gzip and zip file formats. Deflate was created by Phil Katz in the late 1980s as part of the development of the PKZIP file archiving tool.\n",
    "\n",
    "The Deflate algorithm combines two other algorithms, Huffman coding and LZ77, to achieve compression. The LZ77 algorithm is used to find repeated sequences of data in the input, while Huffman coding is used to encode the repeated sequences and the remaining data in a more efficient manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deflate:\n",
    "\n",
    "    @staticmethod\n",
    "    def deflate(input_data):\n",
    "        # Step 1: Compression using LZ77 algorithm\n",
    "        compressed_data = lz77_compress(input_data)\n",
    "        \n",
    "        # Step 2: Huffman coding of literals, lengths, and distances\n",
    "        huffman_codes = huffman_encode(compressed_data)\n",
    "        huffman_encoded_data = apply_huffman_codes(compressed_data, huffman_codes)\n",
    "        \n",
    "        # Step 3: Write block header and data to output stream\n",
    "        block = generate_block(huffman_encoded_data)\n",
    "        \n",
    "        # Print visualization of the compression process\n",
    "        print_compression_info(input_data, compressed_data, huffman_codes, block)\n",
    "        \n",
    "        return block\n",
    "\n",
    "    @staticmethod\n",
    "    def lz77_compress(input_data):\n",
    "        # Implement LZ77 compression algorithm here\n",
    "        # Return compressed data as a list of (distance, length, next_char) tuples\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def huffman_encode(compressed_data):\n",
    "        # Implement Huffman encoding algorithm here\n",
    "        # Return a dictionary of Huffman codes for each literal and length/distance code\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_huffman_codes(compressed_data, huffman_codes):\n",
    "        # Apply Huffman codes to compressed data to generate a sequence of bits\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_block(huffman_encoded_data):\n",
    "        # Generate block header and data for compressed data\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def print_compression_info(input_data, compressed_data, huffman_codes, block):\n",
    "        # Print information about the compression process for visualization\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "\n",
    "Anastasia Pelekh: Huffman, Lz77, Deflated\n",
    "\n",
    "Dmytro Shumskyi: LZW, Lz77, Deflated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
